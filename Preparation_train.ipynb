{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Preparation_train_.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTYbXqbyShcp",
        "outputId": "dedbaa57-461a-408b-9dbe-29d6270e6569"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!pip install pytorch-tabnet transformers\n",
        "\n",
        "import pandas as pd\n",
        "import shutil\n",
        "import os\n",
        "import numpy as np\n",
        "from transformers import BertTokenizer\n",
        "from transformers import BertModel\n",
        "import torch\n",
        "import random\n",
        "import pickle\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-tabnet\n",
            "  Downloading https://files.pythonhosted.org/packages/44/dd/e24309700d20dfc75643d231a3093179652d309cefcadc338e1a20ff288e/pytorch_tabnet-3.0.0-py3-none-any.whl\n",
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/0c/7d5950fcd80b029be0a8891727ba21e0cd27692c407c51261c3c921f6da3/transformers-4.1.1-py3-none-any.whl (1.5MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5MB 21.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>1.4 in /usr/local/lib/python3.6/dist-packages (from pytorch-tabnet) (1.4.1)\n",
            "Requirement already satisfied: torch<2.0,>=1.2 in /usr/local/lib/python3.6/dist-packages (from pytorch-tabnet) (1.7.0+cu101)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.6/dist-packages (from pytorch-tabnet) (1.19.4)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.36 in /usr/local/lib/python3.6/dist-packages (from pytorch-tabnet) (4.41.1)\n",
            "Requirement already satisfied: scikit_learn>0.21 in /usr/local/lib/python3.6/dist-packages (from pytorch-tabnet) (0.22.2.post1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 50.5MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 51.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.8)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch<2.0,>=1.2->pytorch-tabnet) (3.7.4.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch<2.0,>=1.2->pytorch-tabnet) (0.16.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (1.0.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=bc5ad5e31d402665354bee445faf9f13af459ab4d9dcdf943e4ed7dbaa86a266\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: pytorch-tabnet, sacremoses, tokenizers, transformers\n",
            "Successfully installed pytorch-tabnet-3.0.0 sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfRbdASBcEpa"
      },
      "source": [
        "### 1. Загрузка необходимых датасетов"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZbgkzkYvCWno",
        "outputId": "b5a467a9-637b-4e08-d369-06f55a9c116e"
      },
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Pandemic_data_hack/train.csv', sep=';')\n",
        "ed = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Pandemic_data_hack/education.csv', sep=';')\n",
        "ep = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Pandemic_data_hack/employements.csv', sep=';')\n",
        "df_test = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Pandemic_data_hack/test.csv', sep=';')"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (18) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZGbl3x_cefd"
      },
      "source": [
        "####*1.1 Подгрузим дополнительные данные о зраплатах в России по городам. Возьмем рейтинг городов России по средневзвешенной зарплате  1-ое полугодие 2020-го года*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "734WOGye9qOU"
      },
      "source": [
        "df_salary = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Pandemic_data_hack/salary_by_city - salary_by_city - Лист1.csv')\n",
        "df_salary['locality_name'] = df_salary['location']\n",
        "df_salary['salary_count'] = df_salary['salary']\n",
        "df_1 = pd.merge(df, df_salary, how='left', on=\"locality_name\")\n"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0HsaKPoM6x2",
        "outputId": "789ea606-3899-41a7-ca83-e09924300821"
      },
      "source": [
        "df_1.info()"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 306270 entries, 0 to 306269\n",
            "Data columns (total 35 columns):\n",
            " #   Column                      Non-Null Count   Dtype  \n",
            "---  ------                      --------------   -----  \n",
            " 0   id                          306270 non-null  int64  \n",
            " 1   position_x                  306270 non-null  object \n",
            " 2   region                      306258 non-null  object \n",
            " 3   industry                    306270 non-null  object \n",
            " 4   locality                    306270 non-null  int64  \n",
            " 5   locality_name               290778 non-null  object \n",
            " 6   education_type              306270 non-null  object \n",
            " 7   drive_licences              121925 non-null  object \n",
            " 8   citizenship                 306270 non-null  object \n",
            " 9   schedule                    306270 non-null  object \n",
            " 10  employement_type            306270 non-null  object \n",
            " 11  age                         298459 non-null  float64\n",
            " 12  gender                      298497 non-null  object \n",
            " 13  experience                  306270 non-null  int64  \n",
            " 14  salary_desired              306270 non-null  int64  \n",
            " 15  relocation_ready            233567 non-null  object \n",
            " 16  travel_ready                237054 non-null  object \n",
            " 17  retraining_ready            249144 non-null  object \n",
            " 18  is_worldskills_participant  194 non-null     object \n",
            " 19  has_qualifications          2534 non-null    object \n",
            " 20  completeness_rate           306270 non-null  float64\n",
            " 21  creation_date               306263 non-null  object \n",
            " 22  modification_date           306263 non-null  object \n",
            " 23  publish_date                306270 non-null  object \n",
            " 24  salary_x                    306270 non-null  int64  \n",
            " 25  location                    133406 non-null  object \n",
            " 26  salary_y                    133406 non-null  float64\n",
            " 27  salary_count                306270 non-null  float64\n",
            " 28  cluster                     306270 non-null  int32  \n",
            " 29  position_y                  232999 non-null  object \n",
            " 30  employer                    238484 non-null  object \n",
            " 31  achievements                37868 non-null   object \n",
            " 32  responsibilities            306270 non-null  object \n",
            " 33  start_date                  238909 non-null  object \n",
            " 34  finish_date                 206213 non-null  object \n",
            "dtypes: float64(4), int32(1), int64(5), object(25)\n",
            "memory usage: 83.0+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UK7dISnlvO2N",
        "outputId": "1d99e59f-862e-46bf-9d8e-7561e118a71a"
      },
      "source": [
        "#Заполним недостающие значения по городам самым низким показателем зарплат\n",
        "df_1.salary_count.fillna('28500')"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         39800\n",
              "1         34000\n",
              "2         28500\n",
              "3         35900\n",
              "4         46400\n",
              "          ...  \n",
              "306265    28500\n",
              "306266    28500\n",
              "306267    28500\n",
              "306268    30600\n",
              "306269    33200\n",
              "Name: salary_count, Length: 306270, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FmWDZNQ4-RFt",
        "outputId": "9794f3a8-4f7b-4314-c91b-155ca86400f9"
      },
      "source": [
        "# очистим собранные средние зарплаты по городам от недостающих значений\n",
        "\n",
        "df_1['salary_count'].isna().sum()\n",
        "\n",
        "sd_median=df_1['salary_count'].median(skipna = bool)\n",
        "df_1['salary_count']= pd.to_numeric(df_1['salary_count'],errors='coerce')\n",
        "df_1['salary_count']= np.where(np.isnan(pd.to_numeric(df_1['salary_count'],errors='coerce')),sd_median,df_1['salary_count'])\n",
        "\n",
        "sd_median=df_1['salary_count'].median(skipna = bool)\n",
        "df_1['salary_count']= pd.to_numeric(df_1['salary_count'],errors='coerce')\n",
        "df_1['salary_count']= np.where(np.isnan(pd.to_numeric(df_1['salary_count'],errors='coerce')),sd_median,df_1['salary_count'])\n",
        "\n",
        "df_1['salary_count'].isna().sum()"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "172864"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ru1kozW-eO17"
      },
      "source": [
        "###2.Кластеризуем каждое резюме по уровню средней зарплаты, характерной для города или региона"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRqaowCcxBYa"
      },
      "source": [
        "#скалируем данные по зарплатам\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "X=df_1.iloc[:, 27].values.reshape(-1, 1)\n",
        "X=np.nan_to_num(X)\n",
        "Clus_dataSet=StandardScaler().fit_transform(X)"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mvs4dg60BgvM",
        "outputId": "18457211-ed1c-47cd-8fba-c489e13fb475"
      },
      "source": [
        "X=df_1.iloc[:, 27].values\n",
        "print(X)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[39800. 34000. 43800. ... 43800. 30600. 33200.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXx8DZRs9M7x"
      },
      "source": [
        "#кластеризуем с помощью  Kmeans\n",
        "from sklearn.cluster import KMeans\n",
        "clasterNum=10\n",
        "k_maens = KMeans(init=\"k-means++\",n_clusters=clasterNum,n_init=12)\n",
        "k_maens.fit(Clus_dataSet)\n",
        "labels=k_maens.labels_"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cs33l12oJH92"
      },
      "source": [
        "#вот и появился новый признак - кластер, который агрегирует в себе данные по локали \n",
        "#и общем уровне зарплат, характерном для этой локации\n",
        "\n",
        "df_1['cluster'] = labels"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VmMqqe2NurY"
      },
      "source": [
        "#подгрузим датасет о предыдушем опыте работника, где нас особенно интерсует графа с описанием его обязанностей\n",
        "\n",
        "df_1 = pd.merge(df_1, ep, how='left', on=\"id\")"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhYjKuHRQBj5"
      },
      "source": [
        "#почистим признак от шума\n",
        "\n",
        "df_1.responsibilities = df_1.responsibilities.str.replace(r'<(.*?)>', '')\n",
        "df_1.responsibilities = df_1.responsibilities.str.replace('/', '')\n",
        "df_1.responsibilities = df_1.responsibilities.str.replace(',', '')\n",
        "df_1.responsibilities = df_1.responsibilities.str.replace(' +', ' ')\n",
        "df_1.responsibilities = df_1.responsibilities.str.strip()\n",
        "\n",
        "#почистим сведения об обязанностях на предыдущем месте и работы и типе образования от нулевых значений\n",
        "\n",
        "df_1['responsibilities']= np.where( pd.isnull(df_1['responsibilities']),'no responsibilities',df_1['responsibilities'])\n",
        "\n",
        "df_1['education_type']= np.where( pd.isnull(df_1['education_type']),'no education type',df_1['education_type']) "
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOhE7UxXQtQv"
      },
      "source": [
        "df_work = df_1[['id', 'industry', 'employement_type',\n",
        "              'education_type', 'salary_x', 'cluster', 'responsibilities']]"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LTVxxkBgi47"
      },
      "source": [
        "###3. Обучим на Bert векторные представления признака 'responsibilities'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zH1BoUd9U4TD"
      },
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device = torch.device(device)"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uywic9iNV8mh"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('DeepPavlov/rubert-base-cased')\n",
        "bert = BertModel.from_pretrained('DeepPavlov/rubert-base-cased')"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h72tsx9lab3x",
        "outputId": "facb26c2-4a7a-4ca8-93d0-685763835380"
      },
      "source": [
        "#df_work[['responsibilities']] = df_work[['responsibilities']].astype(str)\n",
        "df_work.loc[:, ('responsibilities')] = df_work.loc[:, ('responsibilities')].astype(str)"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:1743: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  isetter(ilocs[0], value)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fA6j7Ccr3d0L",
        "outputId": "a6d4a0e2-f226-4388-d4ef-4b0f1e4513ec"
      },
      "source": [
        "df_work.info()"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 306270 entries, 0 to 306269\n",
            "Data columns (total 7 columns):\n",
            " #   Column            Non-Null Count   Dtype \n",
            "---  ------            --------------   ----- \n",
            " 0   id                306270 non-null  int64 \n",
            " 1   industry          306270 non-null  object\n",
            " 2   employement_type  306270 non-null  object\n",
            " 3   education_type    306270 non-null  object\n",
            " 4   salary_x          306270 non-null  int64 \n",
            " 5   cluster           306270 non-null  int32 \n",
            " 6   responsibilities  306270 non-null  object\n",
            "dtypes: int32(1), int64(2), object(4)\n",
            "memory usage: 17.5+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLPPsKakWIDx",
        "outputId": "64ab8430-7b80-4f66-c4c9-d7aea061dcf7"
      },
      "source": [
        "%%time\n",
        "\n",
        "bert.to(device)\n",
        "bert.eval();\n",
        "\n",
        "step = 10_000\n",
        "responsibilities_vectors = False\n",
        "\n",
        "for batch_i in range(0, len(df_work), step):\n",
        "    batch = df_work.responsibilities[batch_i:batch_i+step]\n",
        "    inputs = tokenizer(\n",
        "        batch.to_list(),\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        max_length=20,\n",
        "        return_tensors='pt',\n",
        "        return_attention_mask=True,\n",
        "    )\n",
        "    inputs.to(device)\n",
        "    with torch.no_grad():\n",
        "        output = bert(**inputs)\n",
        "    total_sum = torch.zeros_like(output[0][:, 1, :])\n",
        "    for i in range(0, output[0].shape[1]):\n",
        "        total_sum += output[0][:, i, :]\n",
        "    total_sum = total_sum / output[0].shape[1]\n",
        "    # responsibilities_vectors.extend(total_sum.detach().cpu().numpy())\n",
        "    total_sum = total_sum.detach().cpu().numpy()\n",
        "    if responsibilities_vectors is False:\n",
        "        responsibilities_vectors = total_sum\n",
        "    else:\n",
        "        responsibilities_vectors = np.vstack((responsibilities_vectors, total_sum))\n",
        "    \n",
        "    if batch_i % 100_000 == 0:\n",
        "        print(batch_i)"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "100000\n",
            "200000\n",
            "300000\n",
            "CPU times: user 7min 47s, sys: 3min 31s, total: 11min 18s\n",
            "Wall time: 11min 18s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVgBoMtImKKu",
        "outputId": "be034528-2ae4-45d5-c54b-3318d114d537"
      },
      "source": [
        "len(responsibilities_vectors[6])\n"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "768"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TAV0YGbIAMGw",
        "outputId": "ace91960-46a1-4292-ed7c-4a0e0f7c8de8"
      },
      "source": [
        "responsibilities_vectors.shape"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(306270, 768)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1gqITksmaoL"
      },
      "source": [
        "np.save('/content/drive/MyDrive/Colab Notebooks/Pandemic_data_hack/input/responsibilities_vectors.npy', responsibilities_vectors)"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PgceoLBWhy1R"
      },
      "source": [
        "###4. Преобразуем в индексы другие признаки"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rg0wlEIJm4dh"
      },
      "source": [
        "cluster = set()\n",
        "education_type = set()\n",
        "employement_type = set()\n",
        "industry = set()\n",
        "\n",
        "cluster.update(df_work.cluster.unique().tolist())\n",
        "education_type.update(df_work.education_type.unique().tolist())\n",
        "employement_type.update(df_work.employement_type.unique().tolist())\n",
        "industry.update(df_work.industry.unique().tolist())"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvD2kKWPswrb"
      },
      "source": [
        "cluster2id = {name:id for id, name in enumerate(cluster)}\n",
        "education_type2id = {name:id for id, name in enumerate(education_type)}\n",
        "employement_type2id = {name:id for id, name in enumerate(employement_type)}\n",
        "industry2id = {name:id for id, name in enumerate(industry)}"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MloUqcH2uo7V",
        "outputId": "25bc9818-5a9d-44e1-8fb2-892a005f8af1"
      },
      "source": [
        "df_work.info()"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 306270 entries, 0 to 306269\n",
            "Data columns (total 7 columns):\n",
            " #   Column            Non-Null Count   Dtype \n",
            "---  ------            --------------   ----- \n",
            " 0   id                306270 non-null  int64 \n",
            " 1   industry          306270 non-null  object\n",
            " 2   employement_type  306270 non-null  object\n",
            " 3   education_type    306270 non-null  object\n",
            " 4   salary_x          306270 non-null  int64 \n",
            " 5   cluster           306270 non-null  int32 \n",
            " 6   responsibilities  306270 non-null  object\n",
            "dtypes: int32(1), int64(2), object(4)\n",
            "memory usage: 17.5+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gefe0Rf5u9Sz"
      },
      "source": [
        "with open('/content/drive/MyDrive/Colab Notebooks/Pandemic_data_hack/input/cluster2id.pickle', 'wb') as handle:\n",
        "    pickle.dump(cluster2id, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/Pandemic_data_hack/input/education_type2id.pickle', 'wb') as handle:\n",
        "    pickle.dump(education_type2id, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/Pandemic_data_hack/input/employement_type2id.pickle', 'wb') as handle:\n",
        "    pickle.dump(employement_type2id, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/Pandemic_data_hack/input/industry2id.pickle', 'wb') as handle:\n",
        "    pickle.dump(industry2id, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQsYFcx5xDv5"
      },
      "source": [
        "cluster_label = []\n",
        "education_type_label = []\n",
        "employement_type_label = []\n",
        "industry_label = []\n",
        "salary_from\t= []\n",
        "\n",
        "for index in df_work.index:\n",
        "    cluster_label.append(cluster2id[df_work.cluster.iloc[index]])\n",
        "    education_type_label.append(education_type2id[df_work.education_type.iloc[index]])\n",
        "    employement_type_label.append(employement_type2id[df_work.employement_type.iloc[index]])\n",
        "    industry_label.append(industry2id[df_work.industry.iloc[index]])\n",
        "    salary_from.append(df_work.salary_x.iloc[index])"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYfO9ACxiJz_"
      },
      "source": [
        "###5.Cохраним наши индексы отдельно в файле"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hApSHRjQy8dM"
      },
      "source": [
        "\n",
        "salary_from = np.array(salary_from)\n",
        "salary_from_scaled = preprocessing.scale(salary_from)"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKhMcI00zAwp",
        "outputId": "16667c76-8d85-4090-f2e1-4f800a83bbd6"
      },
      "source": [
        "salary_from_scaled[22], salary_from[22]"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-0.5334260573415979, 22080)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWzO4Y-FzHXp"
      },
      "source": [
        "np.save('/content/drive/MyDrive/Colab Notebooks/Pandemic_data_hack/input/salary_scaled.npy', salary_from_scaled)\n",
        "np.save('/content/drive/MyDrive/Colab Notebooks/Pandemic_data_hack/input/salary_orig.npy', salary_from)"
      ],
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNUPrfImzTbQ"
      },
      "source": [
        "cluster_label = np.array(cluster_label)\n",
        "education_type_label = np.array(education_type_label)\n",
        "employement_type_label = np.array(employement_type_label)\n",
        "industry_label = np.array(industry_label)"
      ],
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdTEJ1l70WhZ"
      },
      "source": [
        "cluster_label = np.reshape(cluster_label, (cluster_label.shape[0], 1))\n",
        "education_type_label = np.reshape(education_type_label, (education_type_label.shape[0], 1))\n",
        "employement_type_label = np.reshape(employement_type_label, (employement_type_label.shape[0], 1))\n",
        "industry_label = np.reshape(industry_label, (industry_label.shape[0], 1))"
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pCSdiUX0e4m"
      },
      "source": [
        "np.save('/content/drive/MyDrive/Colab Notebooks/Pandemic_data_hack/input/cluster_label.npy', cluster_label)\n",
        "np.save('/content/drive/MyDrive/Colab Notebooks/Pandemic_data_hack/input/education_type_label.npy', education_type_label)\n",
        "np.save('/content/drive/MyDrive/Colab Notebooks/Pandemic_data_hack/input/employement_type_label.npy', employement_type_label)\n",
        "np.save('/content/drive/MyDrive/Colab Notebooks/Pandemic_data_hack/input/industry_label.npy', industry_label)"
      ],
      "execution_count": 121,
      "outputs": []
    }
  ]
}